{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81028f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# XGBOOST - PHISHING URL DETECTION\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"XGBOOST - PHISHING URL DETECTION\")\n",
    "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 1: LOAD PROCESSED DATA\n",
    "# ============================================\n",
    "\n",
    "print(\"LOADING DATA\")\n",
    "\n",
    "# Define paths\n",
    "TRAIN_PATH = '../../../data/processed/url-detection/phishing_features_train.csv'\n",
    "TEST_PATH = '../../../data/processed/url-detection/phishing_features_test.csv'\n",
    "\n",
    "# Load data\n",
    "print(\"\\nLoading training data...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "print(f\"Train data loaded: {train_df.shape[0]:,} rows, {train_df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\nLoading test data...\")\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "print(f\"Test data loaded: {test_df.shape[0]:,} rows, {test_df.shape[1]} columns\")\n",
    "\n",
    "# Prepare data\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Handle missing values\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Encode labels as binary (XGBoost needs 0/1, not strings)\n",
    "# WHAT: Convert 'benign'/'phish' to 0/1\n",
    "# WHY: XGBoost requires numerical labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)  # benign=0, phish=1\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "print(f\"\\nData prepared:\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   y_train: {y_train_encoded.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "print(f\"   y_test: {y_test_encoded.shape}\")\n",
    "print(f\"\\nLabel encoding: benign=0, phish=1\")\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution:\")\n",
    "unique, counts = np.unique(y_train_encoded, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    label_name = 'benign' if label == 0 else 'phish'\n",
    "    print(f\"   {label_name} ({label}): {count:,} ({count/len(y_train_encoded)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 3: BASELINE XGBOOST (NO TUNING)\n",
    "# ============================================\n",
    "\n",
    "print(\"BASELINE XGBOOST (DEFAULT PARAMETERS)\")\n",
    "\n",
    "# Calculate scale_pos_weight for imbalanced data\n",
    "# WHAT: Ratio of negative to positive samples\n",
    "# WHY: Tells XGBoost how to balance the classes\n",
    "# FORMULA: scale_pos_weight = count(negative) / count(positive)\n",
    "n_benign = (y_train_encoded == 0).sum()\n",
    "n_phish = (y_train_encoded == 1).sum()\n",
    "scale_pos_weight = n_benign / n_phish\n",
    "\n",
    "print(f\"\\nClass imbalance handling:\")\n",
    "print(f\"   Benign samples: {n_benign:,}\")\n",
    "print(f\"   Phishing samples: {n_phish:,}\")\n",
    "print(f\"   Scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "print(f\"   → XGBoost will treat phishing {scale_pos_weight:.0f}x more important\")\n",
    "\n",
    "# Train baseline XGBoost\n",
    "print(\"\\nTraining baseline XGBoost...\")\n",
    "baseline_start = datetime.now()\n",
    "\n",
    "baseline_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "baseline_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "baseline_end = datetime.now()\n",
    "baseline_time = (baseline_end - baseline_start).total_seconds()\n",
    "\n",
    "print(f\"Baseline training complete!\")\n",
    "print(f\"Training time: {baseline_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate baseline\n",
    "baseline_pred = baseline_model.predict(X_test)\n",
    "baseline_pred_proba = baseline_model.predict_proba(X_test)[:, 1]\n",
    "baseline_accuracy = accuracy_score(y_test_encoded, baseline_pred)\n",
    "baseline_precision = precision_score(y_test_encoded, baseline_pred)\n",
    "baseline_recall = recall_score(y_test_encoded, baseline_pred)\n",
    "baseline_f1 = f1_score(y_test_encoded, baseline_pred)\n",
    "\n",
    "baseline_roc_auc = roc_auc_score(y_test_encoded, baseline_pred_proba)\n",
    "\n",
    "print(\"\\nBaseline XGBoost Results (No Tuning):\")\n",
    "print(f\"   Accuracy:  {baseline_accuracy*100:.2f}%\")\n",
    "print(f\"   Precision: {baseline_precision*100:.2f}%\")\n",
    "print(f\"   Recall:    {baseline_recall*100:.2f}%\")\n",
    "print(f\"   F1-Score:  {baseline_f1*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 3.5: MANUAL HYPERPARAMETER TUNING (ACCURACY OPTIMIZATION)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MANUAL HYPERPARAMETER TUNING (ACCURACY OPTIMIZATION)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Goal: Maximize Accuracy (Overall Correct Predictions)\n",
    "\n",
    "Current Baseline Performance:\n",
    "   - Accuracy: {:.2%}\n",
    "   - Precision: {:.2%}\n",
    "   - Recall: {:.2%}\n",
    "   - F1-Score: {:.2%}\n",
    "\n",
    "Manual Tuning Strategy:\n",
    "   We'll tune 4 key parameters sequentially, each with 5-fold CV:\n",
    "   \n",
    "   1. scale_pos_weight  → Balance classes for accuracy\n",
    "   2. max_depth         → Model complexity  \n",
    "   3. min_child_weight  → Regularization\n",
    "   4. learning_rate + n_estimators → Final optimization\n",
    "\n",
    "Optimization Metric: Accuracy (correct predictions / total predictions)\n",
    "\"\"\".format(baseline_accuracy, baseline_precision, baseline_recall, baseline_f1))\n",
    "\n",
    "import time\n",
    "\n",
    "# Track tuning start time\n",
    "tuning_start = datetime.now()\n",
    "\n",
    "# ============================================\n",
    "# STEP 3.5.1: TUNE SCALE_POS_WEIGHT\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3.5.1: Tuning scale_pos_weight\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Current baseline value: {scale_pos_weight:.2f}\")\n",
    "print(\"Testing values: [1.5, 2, 2.13, 2.5, 3, 3.5]\")\n",
    "print(\"(Finding optimal balance for maximum accuracy)\\n\")\n",
    "\n",
    "best_accuracy = 0\n",
    "best_weight = scale_pos_weight\n",
    "weight_results = []\n",
    "\n",
    "step_start = time.time()\n",
    "\n",
    "for weight in [1.5, 2, 2.13, 2.5, 3, 3.5]:\n",
    "    print(f\"  Testing scale_pos_weight={weight}...\", end=\" \", flush=True)\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        scale_pos_weight=weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss',\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # 5-fold CV on training data\n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train, y_train_encoded,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    \n",
    "    weight_results.append({\n",
    "        'weight': weight,\n",
    "        'accuracy_mean': mean_accuracy,\n",
    "        'accuracy_std': std_accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_weight = weight\n",
    "\n",
    "step_time = time.time() - step_start\n",
    "\n",
    "print(f\"\\nBest scale_pos_weight: {best_weight}\")\n",
    "print(f\"   CV Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"   Improvement: {(best_accuracy - baseline_accuracy)*100:+.2f}% vs baseline\")\n",
    "print(f\"   Time taken: {step_time:.1f} seconds\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3.5.2: TUNE MAX_DEPTH\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3.5.2: Tuning max_depth\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Using scale_pos_weight={best_weight}\")\n",
    "print(\"Testing values: [4, 5, 6, 7, 8, 10]\\n\")\n",
    "\n",
    "best_accuracy_depth = 0\n",
    "best_depth = 6\n",
    "depth_results = []\n",
    "\n",
    "step_start = time.time()\n",
    "\n",
    "for depth in [4, 5, 6, 7, 8, 10]:\n",
    "    print(f\"  Testing max_depth={depth}...\", end=\" \", flush=True)\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        scale_pos_weight=best_weight,\n",
    "        max_depth=depth,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss',\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train, y_train_encoded,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    \n",
    "    depth_results.append({\n",
    "        'depth': depth,\n",
    "        'accuracy_mean': mean_accuracy,\n",
    "        'accuracy_std': std_accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    \n",
    "    if mean_accuracy > best_accuracy_depth:\n",
    "        best_accuracy_depth = mean_accuracy\n",
    "        best_depth = depth\n",
    "\n",
    "step_time = time.time() - step_start\n",
    "\n",
    "print(f\"\\nBest max_depth: {best_depth}\")\n",
    "print(f\"   CV Accuracy: {best_accuracy_depth:.4f}\")\n",
    "print(f\"   Improvement: {(best_accuracy_depth - best_accuracy)*100:+.2f}% vs previous step\")\n",
    "print(f\"   Time taken: {step_time:.1f} seconds\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3.5.3: TUNE MIN_CHILD_WEIGHT\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3.5.3: Tuning min_child_weight\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Using scale_pos_weight={best_weight}, max_depth={best_depth}\")\n",
    "print(\"Testing values: [1, 2, 3, 5, 7]\\n\")\n",
    "\n",
    "best_accuracy_mcw = 0\n",
    "best_mcw = 1\n",
    "mcw_results = []\n",
    "\n",
    "step_start = time.time()\n",
    "\n",
    "for mcw in [1, 2, 3, 5, 7]:\n",
    "    print(f\"  Testing min_child_weight={mcw}...\", end=\" \", flush=True)\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        scale_pos_weight=best_weight,\n",
    "        max_depth=best_depth,\n",
    "        min_child_weight=mcw,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss',\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train, y_train_encoded,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    \n",
    "    mcw_results.append({\n",
    "        'min_child_weight': mcw,\n",
    "        'accuracy_mean': mean_accuracy,\n",
    "        'accuracy_std': std_accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    \n",
    "    if mean_accuracy > best_accuracy_mcw:\n",
    "        best_accuracy_mcw = mean_accuracy\n",
    "        best_mcw = mcw\n",
    "\n",
    "step_time = time.time() - step_start\n",
    "\n",
    "print(f\"\\nBest min_child_weight: {best_mcw}\")\n",
    "print(f\"   CV Accuracy: {best_accuracy_mcw:.4f}\")\n",
    "print(f\"   Improvement: {(best_accuracy_mcw - best_accuracy_depth)*100:+.2f}% vs previous step\")\n",
    "print(f\"   Time taken: {step_time:.1f} seconds\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3.5.4: TUNE LEARNING_RATE + N_ESTIMATORS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3.5.4: Tuning learning_rate + n_estimators\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Using scale_pos_weight={best_weight}, max_depth={best_depth}, min_child_weight={best_mcw}\\n\")\n",
    "\n",
    "best_accuracy_lr = 0\n",
    "best_lr_config = {'learning_rate': 0.1, 'n_estimators': 100}\n",
    "lr_results = []\n",
    "\n",
    "step_start = time.time()\n",
    "\n",
    "configs = [\n",
    "    {'learning_rate': 0.3, 'n_estimators': 100},\n",
    "    {'learning_rate': 0.1, 'n_estimators': 100},\n",
    "    {'learning_rate': 0.05, 'n_estimators': 200},\n",
    "    {'learning_rate': 0.03, 'n_estimators': 300},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    lr = config['learning_rate']\n",
    "    n_est = config['n_estimators']\n",
    "    print(f\"  Testing lr={lr:.2f}, n_estimators={n_est}...\", end=\" \", flush=True)\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        scale_pos_weight=best_weight,\n",
    "        max_depth=best_depth,\n",
    "        min_child_weight=best_mcw,\n",
    "        learning_rate=lr,\n",
    "        n_estimators=n_est,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss',\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train, y_train_encoded,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    \n",
    "    lr_results.append({\n",
    "        'learning_rate': lr,\n",
    "        'n_estimators': n_est,\n",
    "        'accuracy_mean': mean_accuracy,\n",
    "        'accuracy_std': std_accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    \n",
    "    if mean_accuracy > best_accuracy_lr:\n",
    "        best_accuracy_lr = mean_accuracy\n",
    "        best_lr_config = config\n",
    "\n",
    "step_time = time.time() - step_start\n",
    "\n",
    "print(f\"\\nBest config: lr={best_lr_config['learning_rate']}, n_estimators={best_lr_config['n_estimators']}\")\n",
    "print(f\"   CV Accuracy: {best_accuracy_lr:.4f}\")\n",
    "print(f\"   Improvement: {(best_accuracy_lr - best_accuracy_mcw)*100:+.2f}% vs previous step\")\n",
    "print(f\"   Time taken: {step_time:.1f} seconds\")\n",
    "\n",
    "# ============================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================\n",
    "\n",
    "tuning_end = datetime.now()\n",
    "total_tuning_time = (tuning_end - tuning_start).total_seconds()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MANUAL TUNING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nBEST HYPERPARAMETERS FOUND:\")\n",
    "print(f\"   scale_pos_weight:  {best_weight}\")\n",
    "print(f\"   max_depth:         {best_depth}\")\n",
    "print(f\"   min_child_weight:  {best_mcw}\")\n",
    "print(f\"   learning_rate:     {best_lr_config['learning_rate']}\")\n",
    "print(f\"   n_estimators:      {best_lr_config['n_estimators']}\")\n",
    "\n",
    "print(\"\\nACCURACY PROGRESSION:\")\n",
    "print(f\"   Baseline (default):              {baseline_accuracy:.2%}\")\n",
    "print(f\"   After scale_pos_weight tuning:   {best_accuracy:.2%} ({(best_accuracy-baseline_accuracy)*100:+.2f}%)\")\n",
    "print(f\"   After max_depth tuning:          {best_accuracy_depth:.2%} ({(best_accuracy_depth-baseline_accuracy)*100:+.2f}%)\")\n",
    "print(f\"   After min_child_weight tuning:   {best_accuracy_mcw:.2%} ({(best_accuracy_mcw-baseline_accuracy)*100:+.2f}%)\")\n",
    "print(f\"   After learning_rate tuning:      {best_accuracy_lr:.2%} ({(best_accuracy_lr-baseline_accuracy)*100:+.2f}%)\")\n",
    "\n",
    "print(f\"\\nTOTAL IMPROVEMENT: {(best_accuracy_lr-baseline_accuracy)*100:+.2f}%\")\n",
    "print(f\"   From {baseline_accuracy:.2%} → {best_accuracy_lr:.2%}\")\n",
    "\n",
    "print(f\"\\nTOTAL TUNING TIME: {total_tuning_time:.2f} seconds ({total_tuning_time/60:.2f} minutes)\")\n",
    "\n",
    "print(\"\\nNOTE: These are CV scores on training data.\")\n",
    "print(\"   Final test set evaluation will come next\")\n",
    "\n",
    "# Train the final tuned model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING FINAL TUNED MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_train_start = datetime.now()\n",
    "\n",
    "tuned_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=best_weight,\n",
    "    max_depth=best_depth,\n",
    "    min_child_weight=best_mcw,\n",
    "    learning_rate=best_lr_config['learning_rate'],\n",
    "    n_estimators=best_lr_config['n_estimators'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining on full training set...\")\n",
    "tuned_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "final_train_end = datetime.now()\n",
    "final_train_time = (final_train_end - final_train_start).total_seconds()\n",
    "\n",
    "print(f\"\\nFinal model trained!\")\n",
    "print(f\"   Training time: {final_train_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 3.6: FINAL EVALUATION - TUNED MODEL ON TEST SET\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EVALUATION - TUNED MODEL ON TEST SET (ACCURACY-OPTIMIZED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Make predictions on test set\n",
    "tuned_pred = tuned_model.predict(X_test)\n",
    "tuned_pred_proba = tuned_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "tuned_accuracy = accuracy_score(y_test_encoded, tuned_pred)\n",
    "tuned_precision = precision_score(y_test_encoded, tuned_pred)\n",
    "tuned_recall = recall_score(y_test_encoded, tuned_pred)\n",
    "tuned_f1 = f1_score(y_test_encoded, tuned_pred)\n",
    "tuned_auc = roc_auc_score(y_test_encoded, tuned_pred_proba)\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(f\"\\n{'Metric':<12} {'Baseline':<12} {'Tuned':<12} {'Change':<12}\")\n",
    "print(\"-\" * 48)\n",
    "print(f\"{'Accuracy':<12} {baseline_accuracy*100:>10.2f}%  {tuned_accuracy*100:>10.2f}%  {(tuned_accuracy-baseline_accuracy)*100:>+10.2f}%\")\n",
    "print(f\"{'Precision':<12} {baseline_precision*100:>10.2f}%  {tuned_precision*100:>10.2f}%  {(tuned_precision-baseline_precision)*100:>+10.2f}%\")\n",
    "print(f\"{'Recall':<12} {baseline_recall*100:>10.2f}%  {tuned_recall*100:>10.2f}%  {(tuned_recall-baseline_recall)*100:>+10.2f}%\")\n",
    "print(f\"{'F1-Score':<12} {baseline_f1*100:>10.2f}%  {tuned_f1*100:>10.2f}%  {(tuned_f1-baseline_f1)*100:>+10.2f}%\")\n",
    "print(f\"{'ROC-AUC':<12} {baseline_roc_auc:>11.4f}  {tuned_auc:>11.4f}  {tuned_auc-baseline_roc_auc:>+11.4f}\")\n",
    "\n",
    "# Confusion matrices\n",
    "cm_baseline = confusion_matrix(y_test_encoded, baseline_pred)\n",
    "cm_tuned = confusion_matrix(y_test_encoded, tuned_pred)\n",
    "\n",
    "baseline_tn, baseline_fp, baseline_fn, baseline_tp = cm_baseline.ravel()\n",
    "tuned_tn, tuned_fp, tuned_fn, tuned_tp = cm_tuned.ravel()\n",
    "\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"\\n{'Error Type':<30} {'Baseline':<12} {'Tuned':<12} {'Change':<12}\")\n",
    "print(\"-\" * 66)\n",
    "print(f\"{'False Negatives (Missed Phish)':<30} {baseline_fn:>11,}  {tuned_fn:>11,}  {baseline_fn-tuned_fn:>+11,}\")\n",
    "print(f\"{'False Positives (False Alarm)':<30} {baseline_fp:>11,}  {tuned_fp:>11,}  {baseline_fp-tuned_fp:>+11,}\")\n",
    "print(f\"{'True Negatives (Correct Benign)':<30} {baseline_tn:>11,}  {tuned_tn:>11,}  {tuned_tn-baseline_tn:>+11,}\")\n",
    "print(f\"{'True Positives (Correct Phish)':<30} {baseline_tp:>11,}  {tuned_tp:>11,}  {tuned_tp-baseline_tp:>+11,}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nSummary:\")\n",
    "accuracy_improvement = (tuned_accuracy - baseline_accuracy) * 100\n",
    "f1_improvement = (tuned_f1 - baseline_f1) * 100\n",
    "recall_improvement = (tuned_recall - baseline_recall) * 100\n",
    "precision_improvement = (tuned_precision - baseline_precision) * 100\n",
    "\n",
    "print(f\"   Accuracy:  {baseline_accuracy:.2%} → {tuned_accuracy:.2%} ({accuracy_improvement:+.2f}%)\")\n",
    "print(f\"   F1-Score:  {baseline_f1:.2%} → {tuned_f1:.2%} ({f1_improvement:+.2f}%)\")\n",
    "print(f\"   Precision: {baseline_precision:.2%} → {tuned_precision:.2%} ({precision_improvement:+.2f}%)\")\n",
    "print(f\"   Recall:    {baseline_recall:.2%} → {tuned_recall:.2%} ({recall_improvement:+.2f}%)\")\n",
    "\n",
    "if accuracy_improvement > 0:\n",
    "    print(f\"\\n   Accuracy improved by {accuracy_improvement:.2f} percentage points!\")\n",
    "    total_errors_baseline = baseline_fp + baseline_fn\n",
    "    total_errors_tuned = tuned_fp + tuned_fn\n",
    "    error_reduction = total_errors_baseline - total_errors_tuned\n",
    "    print(f\"   Total errors reduced: {total_errors_baseline:,} → {total_errors_tuned:,} ({error_reduction:+,})\")\n",
    "else:\n",
    "    print(f\"\\n   Accuracy changed by {accuracy_improvement:.2f} percentage points\")\n",
    "\n",
    "# Breakdown of changes\n",
    "print(f\"\\nDetailed Changes:\")\n",
    "additional_caught = tuned_tp - baseline_tp\n",
    "additional_missed = tuned_fn - baseline_fn\n",
    "additional_fp = tuned_fp - baseline_fp\n",
    "additional_tn = tuned_tn - baseline_tn\n",
    "\n",
    "if additional_caught > 0:\n",
    "    print(f\"   Caught {additional_caught:+,} more phishing URLs\")\n",
    "elif additional_caught < 0:\n",
    "    print(f\"   Caught {additional_caught:,} fewer phishing URLs\")\n",
    "\n",
    "if additional_missed < 0:\n",
    "    print(f\"   Missed {abs(additional_missed):,} fewer phishing URLs\")\n",
    "elif additional_missed > 0:\n",
    "    print(f\"   Missed {additional_missed:+,} more phishing URLs\")\n",
    "\n",
    "if additional_fp < 0:\n",
    "    print(f\"   {abs(additional_fp):,} fewer false alarms\")\n",
    "elif additional_fp > 0:\n",
    "    print(f\"   {additional_fp:+,} more false alarms\")\n",
    "\n",
    "print(f\"\\nBest Parameters: spw={best_weight}, depth={best_depth}, mcw={best_mcw}, lr={best_lr_config['learning_rate']}, n={best_lr_config['n_estimators']}\")\n",
    "\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cae236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust prediction threshold instead of retraining\n",
    "for threshold in [0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]:\n",
    "    pred_adjusted = (tuned_pred_proba >= threshold).astype(int)\n",
    "    recall = recall_score(y_test_encoded, pred_adjusted)\n",
    "    precision = precision_score(y_test_encoded, pred_adjusted)\n",
    "    accuracy = accuracy_score(y_test_encoded, pred_adjusted)\n",
    "    f1 = f1_score(y_test_encoded, pred_adjusted)\n",
    "    \n",
    "    print(f\"Threshold {threshold}: Recall={recall:.2%}, Precision={precision:.2%}, F1={f1:.2%}, Accuracy={accuracy:.2%}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0211922",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0.4\n",
    "final_pred = (tuned_pred_proba >= best_threshold).astype(int)\n",
    "final_accuracy = accuracy_score(y_test_encoded, final_pred)\n",
    "final_precision = precision_score(y_test_encoded, final_pred)\n",
    "final_recall = recall_score(y_test_encoded, final_pred)\n",
    "final_f1 = f1_score(y_test_encoded, final_pred)\n",
    "\n",
    "print(f\"Final Model: Threshold={best_threshold}, Accuracy={final_accuracy:.2%}, Precision={final_precision:.2%}, Recall={final_recall:.2%}, F1={final_f1:.2%}\")\n",
    "\n",
    "#save optimized threshold\n",
    "optimal_config = {\n",
    "    'threshold': best_threshold,\n",
    "    'accuracy': final_accuracy,\n",
    "    'precision': final_precision,\n",
    "    'recall': final_recall,\n",
    "    'f1': final_f1\n",
    "}\n",
    "import json\n",
    "with open('xgboost_optimal_threshold.json', 'w') as f:\n",
    "    json.dump(optimal_config, f)\n",
    "\n",
    "print(f\"\\nOptimal threshold saved to xgboost_optimal_threshold.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 4: CONFUSION MATRIX\n",
    "# ============================================\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, final_pred)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  True Negatives (TN):  {cm[0,0]:,} - Correctly identified benign\")\n",
    "print(f\"  False Positives (FP): {cm[0,1]:,} - Benign wrongly flagged as phishing\")\n",
    "print(f\"  False Negatives (FN): {cm[1,0]:,} - Phishing missed!\")\n",
    "print(f\"  True Positives (TP):  {cm[1,1]:,} - Correctly identified phishing\")\n",
    "\n",
    "# Compare with Random Forest\n",
    "print(\"\\nComparison with Random Forest:\")\n",
    "print(f\"  False Negatives: RF: 1,089 → XGB: {cm[1,0]:,} ({cm[1,0]-1089:+,})\")\n",
    "print(f\"  False Positives: RF: 801 → XGB: {cm[0,1]:,} ({cm[0,1]-801:+,})\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Benign', 'Phishing'],\n",
    "            yticklabels=['Benign', 'Phishing'])\n",
    "plt.title('Confusion Matrix - XGBoost (Tuned)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Error rates\n",
    "fpr = cm[0,1] / (cm[0,0] + cm[0,1])\n",
    "fnr = cm[1,0] / (cm[1,0] + cm[1,1])\n",
    "\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"  False Positive Rate: {fpr*100:.2f}% (benign marked as phishing)\")\n",
    "print(f\"  False Negative Rate: {fnr*100:.2f}% (phishing that slipped through)\")\n",
    "print(f\"\\n  Comparison:\")\n",
    "print(f\"  FPR: RF: 2.67% → XGB: {fpr*100:.2f}% ({fpr*100-2.67:+.2f}%)\")\n",
    "print(f\"  FNR: RF: 16.16% → XGB: {fnr*100:.2f}% ({fnr*100-16.16:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 5: ROC CURVE\n",
    "# ============================================\n",
    "\n",
    "print(\"ROC CURVE\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr_roc, tpr_roc, _ = roc_curve(y_test_encoded, tuned_pred_proba)\n",
    "\n",
    "print(f\"\\nROC AUC Score: {baseline_roc_auc:.4f}\")\n",
    "print(f\"   Random Forest: 0.9795\")\n",
    "print(f\"   XGBoost: {baseline_roc_auc:.4f}\")\n",
    "print(f\"   Improvement: {baseline_roc_auc-0.9795:+.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_roc, tpr_roc, color='darkorange', lw=2,\n",
    "         label=f'XGBoost (AUC = {baseline_roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
    "         label='Random Classifier (AUC = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
    "plt.title('ROC Curve - XGBoost vs Random Forest', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 6: FEATURE IMPORTANCE\n",
    "# ============================================\n",
    "\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "\n",
    "# Get feature importances\n",
    "feature_names = X_train.columns.tolist()\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': tuned_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_20 = feature_importance.head(20)\n",
    "plt.barh(range(len(top_20)), top_20['importance'])\n",
    "plt.yticks(range(len(top_20)), top_20['feature'])\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Top 20 Feature Importances - XGBoost', fontsize=16, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 7: SAVE MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"SAVING MODEL\")\n",
    "\n",
    "# Save model\n",
    "model_dir = '../../../models/url-detection'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the XGBoost model\n",
    "model_path = os.path.join(model_dir, 'xgboost.pkl')\n",
    "print(f\"\\nSaving model to: {model_path}\")\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(tuned_model, f)\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "# Model size\n",
    "model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "print(f\"\\nModel file size: {model_size:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
