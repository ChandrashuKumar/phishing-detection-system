{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683eb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CHARACTER-LEVEL CNN WITH ATTENTION\n",
    "# PHISHING URL DETECTION\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CHARACTER-LEVEL CNN WITH ATTENTION\")\n",
    "print(\"PHISHING URL DETECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GPU SETUP AND VERIFICATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\nUsing GPU for training\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"\\nWARNING: GPU not available, using CPU\")\n",
    "    \n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# LOAD DATA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "TRAIN_PATH = '../../../data/processed/url-detection/phishing_features_train.csv'\n",
    "TEST_PATH = '../../../data/processed/url-detection/phishing_features_test.csv'\n",
    "\n",
    "print(\"\\nLoading CSV files...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(f\"Train: {train_df.shape[0]:,} samples\")\n",
    "print(f\"Test: {test_df.shape[0]:,} samples\")\n",
    "\n",
    "# For deep learning, we only need URL and label (not the engineered features)\n",
    "# Load original URLs from dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"\\nLoading original URLs from PhreshPhish...\")\n",
    "dataset = load_dataset(\"phreshphish/phreshphish\", cache_dir='E:/.cache/huggingface')\n",
    "\n",
    "train_urls = [dataset['train'][i]['url'] for i in range(len(dataset['train']))]\n",
    "test_urls = [dataset['test'][i]['url'] for i in range(len(dataset['test']))]\n",
    "train_labels = train_df['label'].values\n",
    "test_labels = test_df['label'].values\n",
    "\n",
    "print(f\"URLs loaded: {len(train_urls):,} train, {len(test_urls):,} test\")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_labels)  # benign=0, phish=1\n",
    "y_test = le.transform(test_labels)\n",
    "\n",
    "print(f\"\\nLabel distribution (train):\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    label_name = 'benign' if label == 0 else 'phish'\n",
    "    print(f\"  {label_name}: {count:,} ({count/len(y_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CHARACTER-LEVEL TOKENIZATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHARACTER TOKENIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Build character vocabulary\n",
    "all_urls = train_urls + test_urls\n",
    "all_chars = set(''.join(all_urls))\n",
    "char_to_idx = {char: idx + 1 for idx, char in enumerate(sorted(all_chars))}\n",
    "char_to_idx['<PAD>'] = 0  # Padding token\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "print(f\"Vocabulary size: {vocab_size} characters\")\n",
    "print(f\"Sample characters: {list(char_to_idx.keys())[:20]}\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_url(url, char_to_idx, max_length=200):\n",
    "    tokens = [char_to_idx.get(char, 0) for char in url[:max_length]]\n",
    "    if len(tokens) < max_length:\n",
    "        tokens += [0] * (max_length - len(tokens))\n",
    "    return tokens\n",
    "\n",
    "MAX_URL_LENGTH = 200\n",
    "print(f\"\\nMax URL length: {MAX_URL_LENGTH} characters\")\n",
    "\n",
    "# Tokenize all URLs\n",
    "print(\"\\nTokenizing URLs...\")\n",
    "X_train = np.array([tokenize_url(url, char_to_idx, MAX_URL_LENGTH) for url in tqdm(train_urls, desc=\"Train\")])\n",
    "X_test = np.array([tokenize_url(url, char_to_idx, MAX_URL_LENGTH) for url in tqdm(test_urls, desc=\"Test\")])\n",
    "\n",
    "print(f\"\\nTokenized shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539477be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PYTORCH DATASET CLASS\n",
    "# ============================================\n",
    "\n",
    "class URLDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.LongTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = URLDataset(X_train, y_train)\n",
    "test_dataset = URLDataset(X_test, y_test)\n",
    "\n",
    "# Calculate class weights for imbalance\n",
    "n_benign = (y_train == 0).sum()\n",
    "n_phish = (y_train == 1).sum()\n",
    "pos_weight = torch.tensor([n_benign / n_phish]).to(device)\n",
    "\n",
    "print(f\"\\nClass weight (phishing): {pos_weight.item():.2f}\")\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 256 if torch.cuda.is_available() else 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84823a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ATTENTION MECHANISM\n",
    "# ============================================\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        attention_weights = torch.softmax(self.attention(x), dim=1)\n",
    "        # attention_weights shape: (batch, seq_len, 1)\n",
    "        \n",
    "        # Apply attention\n",
    "        weighted = x * attention_weights\n",
    "        # weighted shape: (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        return weighted, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CNN ARCHITECTURE\n",
    "# ============================================\n",
    "\n",
    "class PhishingCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, num_filters=256):\n",
    "        super(PhishingCNN, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Multiple parallel convolution layers with different kernel sizes\n",
    "        self.conv3 = nn.Conv1d(embedding_dim, num_filters, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(embedding_dim, num_filters, kernel_size=5, padding=2)\n",
    "        self.conv7 = nn.Conv1d(embedding_dim, num_filters, kernel_size=7, padding=3)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Additional conv layer\n",
    "        self.conv_combine = nn.Conv1d(num_filters * 3, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = AttentionLayer(512)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len)\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)\n",
    "        # x shape: (batch, seq_len, embedding_dim)\n",
    "        \n",
    "        # Transpose for conv1d (expects channels first)\n",
    "        x = x.transpose(1, 2)\n",
    "        # x shape: (batch, embedding_dim, seq_len)\n",
    "        \n",
    "        # Parallel convolutions\n",
    "        conv3_out = self.relu(self.conv3(x))\n",
    "        conv5_out = self.relu(self.conv5(x))\n",
    "        conv7_out = self.relu(self.conv7(x))\n",
    "        \n",
    "        # Concatenate\n",
    "        x = torch.cat([conv3_out, conv5_out, conv7_out], dim=1)\n",
    "        # x shape: (batch, num_filters*3, seq_len)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Additional conv layer\n",
    "        x = self.relu(self.conv_combine(x))\n",
    "        # x shape: (batch, 512, seq_len)\n",
    "        \n",
    "        # Transpose back for attention\n",
    "        x = x.transpose(1, 2)\n",
    "        # x shape: (batch, seq_len, 512)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        x, attention_weights = self.attention(x)\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = torch.max(x, dim=1)[0]\n",
    "        # x shape: (batch, 512)\n",
    "        \n",
    "        # Dense layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        # x shape: (batch, 1)\n",
    "        \n",
    "        return x.squeeze(), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150fb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# INITIALIZE MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = PhishingCNN(vocab_size=vocab_size, embedding_dim=128, num_filters=256)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Loss function with class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "print(f\"\\nOptimizer: Adam (lr=0.001)\")\n",
    "print(f\"Loss: BCEWithLogitsLoss (pos_weight={pos_weight.item():.2f})\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch_X, batch_y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs, _ = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        loss.backward()  #calc gradients\n",
    "        optimizer.step()  #update weights\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, accuracy, f1, recall\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            outputs, _ = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = probs > 0.5\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, accuracy, precision, recall, f1, all_preds, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRAINING LOOP\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "best_f1 = 0\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [], 'train_f1': [], 'train_recall': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [], 'val_f1': []\n",
    "}\n",
    "\n",
    "print(f\"\\nTraining for {NUM_EPOCHS} epochs...\")\n",
    "training_start = datetime.now()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc, train_f1, train_recall = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test\n",
    "    val_loss, val_acc, val_prec, val_recall, val_f1, _, _ = evaluate(\n",
    "        model, test_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_f1)  # update learning rate\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['train_recall'].append(train_recall)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_precision'].append(val_prec)\n",
    "    history['val_recall'].append(val_recall)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}%, F1: {train_f1*100:.2f}%, Recall: {train_recall*100:.2f}%\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%, Prec: {val_prec*100:.2f}%, Recall: {val_recall*100:.2f}%, F1: {val_f1*100:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), '../../../models/url-detection/cnn_best.pth')\n",
    "        print(f\"Best model saved! (F1: {best_f1*100:.2f}%)\")\n",
    "\n",
    "training_end = datetime.now()\n",
    "training_time = (training_end - training_start).total_seconds()\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Total training time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Best validation F1: {best_f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a643c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TEST DIFFERENT THRESHOLDS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING DIFFERENT THRESHOLDS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('../../../models/url-detection/cnn_best.pth'))\n",
    "print(\"Best model loaded\")\n",
    "\n",
    "# Final evaluation\n",
    "_, test_acc, test_prec, test_recall, test_f1, y_pred, y_probs = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Test thresholds from 0.3 to 0.7 in steps of 0.05\n",
    "test_thresholds = [0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "\n",
    "print(f\"\\n{'Threshold':<12} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for thresh in test_thresholds:\n",
    "    y_pred_thresh = (np.array(y_probs) >= thresh).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred_thresh)\n",
    "    prec = precision_score(y_test, y_pred_thresh)\n",
    "    rec = recall_score(y_test, y_pred_thresh)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    \n",
    "    print(f\"{thresh:<12.2f} {acc*100:<12.2f} {prec*100:<12.2f} {rec*100:<12.2f} {f1*100:<12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# LOAD BEST MODEL AND FINAL EVALUATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('../../../models/url-detection/cnn_best.pth'))\n",
    "print(\"Best model loaded\")\n",
    "\n",
    "# Get predictions with default threshold first\n",
    "_, test_acc_default, test_prec_default, test_recall_default, test_f1_default, _, y_probs = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Apply optimized threshold\n",
    "OPTIMAL_THRESHOLD = 0.60\n",
    "\n",
    "y_pred_optimized = (np.array(y_probs) >= OPTIMAL_THRESHOLD).astype(int)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_pred_optimized)\n",
    "test_prec = precision_score(y_test, y_pred_optimized)\n",
    "test_recall = recall_score(y_test, y_pred_optimized)\n",
    "test_f1 = f1_score(y_test, y_pred_optimized)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nWith Default Threshold (0.5):\")\n",
    "print(f\"  Accuracy:  {test_acc_default*100:.2f}%\")\n",
    "print(f\"  Precision: {test_prec_default*100:.2f}%\")\n",
    "print(f\"  Recall:    {test_recall_default*100:.2f}%\")\n",
    "print(f\"  F1-Score:  {test_f1_default*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nWith Optimized Threshold ({OPTIMAL_THRESHOLD}):\")\n",
    "print(f\"  Accuracy:  {test_acc*100:.2f}%\")\n",
    "print(f\"  Precision: {test_prec*100:.2f}%\")\n",
    "print(f\"  Recall:    {test_recall*100:.2f}%\")\n",
    "print(f\"  F1-Score:  {test_f1*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nImprovement from threshold tuning:\")\n",
    "print(f\"  Precision: {(test_prec - test_prec_default)*100:+.2f}%\")\n",
    "print(f\"  Recall:    {(test_recall - test_recall_default)*100:+.2f}%\")\n",
    "print(f\"  F1-Score:  {(test_f1 - test_f1_default)*100:+.2f}%\")\n",
    "\n",
    "# Compare with XGBoost\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON WITH XGBOOST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nXGBoost (TF-IDF + Manual):\")\n",
    "print(f\"  Accuracy:  95.20%\")\n",
    "print(f\"  Precision: 86.25%\")\n",
    "print(f\"  Recall:    87.83%\")\n",
    "print(f\"  F1-Score:  87.03%\")\n",
    "\n",
    "print(f\"\\nCNN with Attention (Optimized Threshold={OPTIMAL_THRESHOLD}):\")\n",
    "print(f\"  Accuracy:  {test_acc*100:.2f}%\")\n",
    "print(f\"  Precision: {test_prec*100:.2f}%\")\n",
    "print(f\"  Recall:    {test_recall*100:.2f}%\")\n",
    "print(f\"  F1-Score:  {test_f1*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nImprovement over XGBoost:\")\n",
    "print(f\"  Accuracy:  {test_acc*100-95.20:+.2f}%\")\n",
    "print(f\"  Precision: {test_prec*100-86.25:+.2f}%\")\n",
    "print(f\"  Recall:    {test_recall*100-87.83:+.2f}%\")\n",
    "print(f\"  F1-Score:  {test_f1*100-87.03:+.2f}%\")\n",
    "\n",
    "# Save optimal threshold\n",
    "import json\n",
    "optimal_config = {\n",
    "    'model': 'CNN (URL-only)',\n",
    "    'threshold': OPTIMAL_THRESHOLD,\n",
    "    'accuracy': float(test_acc),\n",
    "    'precision': float(test_prec),\n",
    "    'recall': float(test_recall),\n",
    "    'f1_score': float(test_f1)\n",
    "}\n",
    "\n",
    "with open('../../../models/url-detection/cnn_url_optimal_threshold.json', 'w') as f:\n",
    "    json.dump(optimal_config, f, indent=2)\n",
    "\n",
    "print(f\"\\nOptimal threshold configuration saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFUSION MATRIX\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_optimized)\n",
    "\n",
    "print(f\"\\nTrue Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"False Positives: {cm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"True Positives:  {cm[1,1]:,}\")\n",
    "\n",
    "fpr = cm[0,1] / (cm[0,0] + cm[0,1])\n",
    "fnr = cm[1,0] / (cm[1,0] + cm[1,1])\n",
    "\n",
    "print(f\"\\nFalse Positive Rate: {fpr*100:.2f}%\")\n",
    "print(f\"False Negative Rate: {fnr*100:.2f}%\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Benign', 'Phishing'],\n",
    "            yticklabels=['Benign', 'Phishing'])\n",
    "plt.title('Confusion Matrix - CNN with Attention', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520861a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ROC CURVE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ROC CURVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "fpr_roc, tpr_roc, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_roc, tpr_roc, color='darkorange', lw=2,\n",
    "         label=f'CNN (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
    "         label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve - CNN with Attention', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617371be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRAINING CURVES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING CURVES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train')\n",
    "axes[0, 0].plot(history['val_loss'], label='Validation')\n",
    "axes[0, 0].set_title('Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot([x*100 for x in history['train_acc']], label='Train')\n",
    "axes[0, 1].plot([x*100 for x in history['val_acc']], label='Validation')\n",
    "axes[0, 1].set_title('Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 0].plot([x*100 for x in history['train_recall']], label='Train')\n",
    "axes[1, 0].plot([x*100 for x in history['val_recall']], label='Validation')\n",
    "axes[1, 0].set_title('Recall')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Recall (%)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# F1-Score\n",
    "axes[1, 1].plot([x*100 for x in history['train_f1']], label='Train')\n",
    "axes[1, 1].plot([x*100 for x in history['val_f1']], label='Validation')\n",
    "axes[1, 1].set_title('F1-Score')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('F1-Score (%)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fca884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer_path = '../../../models/url-detection/char_tokenizer.pkl'\n",
    "with open(tokenizer_path, 'wb') as f:\n",
    "    pickle.dump({'char_to_idx': char_to_idx, 'max_length': MAX_URL_LENGTH}, f)\n",
    "print(f\"Tokenizer saved: {tokenizer_path}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'model': 'CNN with Attention',\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_precision': float(test_prec),\n",
    "    'test_recall': float(test_recall),\n",
    "    'test_f1': float(test_f1),\n",
    "    'roc_auc': float(roc_auc),\n",
    "    'total_params': total_params,\n",
    "    'trained_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_path = '../../../models/url-detection/cnn_metrics.csv'\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "print(f\"Metrics saved: {metrics_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
